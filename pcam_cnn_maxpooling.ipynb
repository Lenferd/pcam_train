{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pcam_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/allnes/pcam_train/blob/master/pcam_cnn_maxpooling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcozEEXAmf2h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "a10963c3-9cdd-4aab-948c-0bcbc198f224"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%pip install keras-metrics"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Collecting keras-metrics\n",
            "  Downloading https://files.pythonhosted.org/packages/32/c9/a87420da8e73de944e63a8e9cdcfb1f03ca31a7c4cdcdbd45d2cdf13275a/keras_metrics-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from keras-metrics) (2.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.3.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.17.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.1.0)\n",
            "Installing collected packages: keras-metrics\n",
            "Successfully installed keras-metrics-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkVdE6rYm0Wa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "565827a8-4920-475b-ed3c-94f23c8b3e45"
      },
      "source": [
        "cd  '/content/drive/My Drive/DL_PCAM'"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/DL_PCAM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3r9MkNP9cNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gzip\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from keras.utils import HDF5Matrix, normalize\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout, Activation\n",
        "from keras.regularizers import l2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras_metrics as ksm\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_57RzhGim196",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "e0b5ed3b-c667-47a5-e523-c735ce2707f0"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "camelyonpatch_level_2_split_test_meta.csv\n",
            "camelyonpatch_level_2_split_test_x.h5\n",
            "camelyonpatch_level_2_split_test_x.h5.gz\n",
            "camelyonpatch_level_2_split_test_y.h5\n",
            "camelyonpatch_level_2_split_test_y.h5.gz\n",
            "camelyonpatch_level_2_split_train_meta.csv\n",
            "camelyonpatch_level_2_split_train_x.h5\n",
            "camelyonpatch_level_2_split_train_x.h5.gz\n",
            "camelyonpatch_level_2_split_train_y.h5\n",
            "camelyonpatch_level_2_split_train_y.h5.gz\n",
            "camelyonpatch_level_2_split_valid_meta.csv\n",
            "camelyonpatch_level_2_split_valid_x.h5\n",
            "camelyonpatch_level_2_split_valid_x.h5.gz\n",
            "camelyonpatch_level_2_split_valid_y.h5\n",
            "camelyonpatch_level_2_split_valid_y.h5.gz\n",
            "model.png\n",
            "\u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXlrVhxJm3do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def uzip_file(file_name, origin_name):\n",
        "  with gzip.open(file_name, 'rb') as f_in:\n",
        "      with open(origin_name, 'wb') as f_out:\n",
        "          shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "# uzip_file(train_x_name + '.gz', train_x_name)\n",
        "# uzip_file(train_y_name + '.gz', train_y_name)\n",
        "\n",
        "# uzip_file(test_x_name + '.gz', test_x_name)\n",
        "# uzip_file(test_y_name + '.gz', test_y_name)\n",
        "\n",
        "# uzip_file(valid_x_name + '.gz', valid_x_name)\n",
        "# uzip_file(valid_y_name + '.gz', valid_y_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMAGHEyDm5sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x_name = 'camelyonpatch_level_2_split_train_x.h5'\n",
        "train_y_name = 'camelyonpatch_level_2_split_train_y.h5'\n",
        "\n",
        "test_x_name = 'camelyonpatch_level_2_split_test_x.h5'\n",
        "test_y_name = 'camelyonpatch_level_2_split_test_y.h5'\n",
        "\n",
        "valid_x_name = 'camelyonpatch_level_2_split_valid_x.h5'\n",
        "valid_y_name = 'camelyonpatch_level_2_split_valid_y.h5'\n",
        "\n",
        "meta_train_name = 'camelyonpatch_level_2_split_train_meta.csv'\n",
        "meta_valid_name = 'camelyonpatch_level_2_split_valid_meta.csv'\n",
        "meta_test_name  = 'camelyonpatch_level_2_split_test_meta.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Kntkpnkm7VM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "ab226816-9d61-40e6-8746-12507530bee8"
      },
      "source": [
        "iter_delta = 2000\n",
        "x_train = np.array\n",
        "y_train = np.array\n",
        "for i in range(1, len(train_x_name), iter_delta):\n",
        "    x_train += np.array(HDF5Matrix(train_x_name, 'x', \n",
        "                                   start=i, \n",
        "                                   end=i + (iter_delta / 2)))\n",
        "    y_train += np.array(HDF5Matrix(train_y_name, 'y', \n",
        "                                   start=i, \n",
        "                                   end=i + (iter_delta / 2)))\n",
        "\n",
        "x_valid = HDF5Matrix(valid_x_name, 'x')\n",
        "y_valid = HDF5Matrix(valid_y_name, 'y')\n",
        "\n",
        "x_test = HDF5Matrix(test_x_name, 'x')\n",
        "y_test = HDF5Matrix(test_y_name, 'y')\n",
        "\n",
        "meta_train = pd.read_csv(meta_train_name)\n",
        "meta_valid = pd.read_csv(meta_valid_name)\n",
        "meta_test  = pd.read_csv(meta_test_name)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-776577468293>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0miter_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_delta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     x_train += np.array(HDF5Matrix(train_x_name, 'x', \n",
            "\u001b[0;31mTypeError\u001b[0m: Required argument 'object' (pos 1) not found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hq5Ys3Cm_-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(x_train))\n",
        "print(type(x_train))\n",
        "print(type(x_train[0]))\n",
        "print(x_train[0].shape)\n",
        "\n",
        "for i in range(0, 9):\n",
        "\t\tpyplot.subplot(330 + 1 + i)\n",
        "\t\tpyplot.imshow(x_train[i], cmap=pyplot.get_cmap('gray'))\n",
        "pyplot.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubgVQHApnCT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "current_core = 32\n",
        "full_size = current_core * current_core * 3\n",
        "original_shape = (96, 96, 3)\n",
        "new_shape = (current_core, current_core, 3)\n",
        "new_size = (current_core, current_core)\n",
        "\n",
        "\n",
        "def resize_for_train(x_array, x_shape):\n",
        "  return np.array([cv.resize(elem, dsize=x_shape) for elem in x_array])\n",
        "x_train = resize_for_train(x_train, new_size)\n",
        "x_valid = resize_for_train(x_valid, new_size)\n",
        "x_test  = resize_for_train(x_test,  new_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG44ZHO0nAkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def plot_metrics(code_metrics, name_metrics):\n",
        "    plt.plot(history.history[code_metrics])\n",
        "    plt.plot(history.history['val_' + code_metrics])\n",
        "    plt.title('Model ' + name_metrics)\n",
        "    plt.ylabel(name_metrics)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "def show_metrics(list_metrics, name_stage, name_model):\n",
        "    name_metrics = ['accuracy', 'precision', 'recall', 'f1-score']\n",
        "    for i in range(4):\n",
        "        print(name_model + ' ' + name_stage + ' ' + \n",
        "              name_metrics[i] + ' : ' + str(list_metrics[i + 1] * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZNXxRk-nFIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name_model = 'CNN with MaxPooling'\n",
        "model = Sequential([\n",
        "    # --------------------------------------------------------------------#\n",
        "    # CONV => RELU => POOL\n",
        "\t\tConv2D(32, (3, 3), padding=\"same\", input_shape=new_shape),\n",
        "\t\tActivation(\"relu\"),\n",
        "\t\tBatchNormalization(),\n",
        "\t\tMaxPooling2D(pool_size=(3, 3)),\n",
        "\t\tDropout(0.25),\n",
        "    # --------------------------------------------------------------------#\n",
        "\t\t# (CONV => RELU) * 2 => POOL\n",
        "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
        "\t\tActivation(\"relu\"),\n",
        "\t\tBatchNormalization(),\n",
        "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
        "\t\tActivation(\"relu\"),\n",
        "\t\tBatchNormalization(),\n",
        "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
        "\t\tDropout(0.25),\n",
        "    # --------------------------------------------------------------------#\n",
        "\t\t# (CONV => RELU) * 2 => POOL\n",
        "\t\tConv2D(128, (3, 3), padding=\"same\"),\n",
        "\t\tActivation(\"relu\"),\n",
        "\t\tBatchNormalization(),\n",
        "\t\tConv2D(128, (3, 3), padding=\"same\"),\n",
        "\t\tActivation(\"relu\"),\n",
        "\t\tBatchNormalization(),\n",
        "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
        "    # --------------------------------------------------------------------#\n",
        "    Flatten(),\n",
        "\t\tDense(1024),\n",
        "\t\tActivation(\"relu\"),\n",
        "\t\tBatchNormalization(),\n",
        "\t\tDropout(0.5),\n",
        "\t\tDense(1),\n",
        "\t\tActivation(\"sigmoid\"),\n",
        "    # --------------------------------------------------------------------#\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy', optimizer='sgd', \n",
        "              metrics = ['binary_accuracy', \n",
        "                         ksm.binary_precision(), \n",
        "                         ksm.binary_recall(),\n",
        "                         ksm.binary_f1_score()\n",
        "                        ]\n",
        "             )\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_train = y_train.reshape((y_train.shape[0], 1))\n",
        "\n",
        "y_valid = np.array(y_valid)\n",
        "y_valid = y_valid.reshape((y_valid.shape[0], 1))\n",
        "\n",
        "y_test = np.array(y_test)\n",
        "y_test = y_test.reshape((y_test.shape[0], 1))\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "              preprocessing_function=lambda x: x/255.,\n",
        "              width_shift_range=2,   # randomly shift images horizontally\n",
        "              height_shift_range=2,  # randomly shift images vertically \n",
        "              horizontal_flip=True,  # randomly flip images\n",
        "              vertical_flip=True)    # randomly flip images\n",
        "\n",
        "batch_size = 32\n",
        "history = model.fit_generator(\n",
        "    datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "    steps_per_epoch=len(x_train) // batch_size,\n",
        "    epochs=4, \n",
        "    shuffle='batch', \n",
        "    use_multiprocessing=True,\n",
        "    validation_data=datagen.flow(x_valid, y_valid, batch_size=batch_size)\n",
        "    )\n",
        "\n",
        "plot_metrics('loss', 'Loss')\n",
        "plot_metrics('binary_accuracy',  'Accuracy')\n",
        "\n",
        "show_metrics(model.evaluate(x_train, y_train), 'train', name_model)\n",
        "show_metrics(model.evaluate(x_valid, y_valid), 'valid', name_model)\n",
        "show_metrics(model.evaluate(x_test,  y_test),  'test',  name_model)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}