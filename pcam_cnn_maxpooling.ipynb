{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pcam_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/allnes/pcam_train/blob/master/pcam_cnn_maxpooling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcozEEXAmf2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%pip install keras-metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkVdE6rYm0Wa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd  '/content/drive/My Drive/DL_PCAM'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_57RzhGim196",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXlrVhxJm3do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gzip\n",
        "import shutil\n",
        "def uzip_file(file_name, origin_name):\n",
        "  with gzip.open(file_name, 'rb') as f_in:\n",
        "      with open(origin_name, 'wb') as f_out:\n",
        "          shutil.copyfileobj(f_in, f_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMAGHEyDm5sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x_name = 'camelyonpatch_level_2_split_train_x.h5'\n",
        "train_y_name = 'camelyonpatch_level_2_split_train_y.h5'\n",
        "\n",
        "test_x_name = 'camelyonpatch_level_2_split_test_x.h5'\n",
        "test_y_name = 'camelyonpatch_level_2_split_test_y.h5'\n",
        "\n",
        "valid_x_name = 'camelyonpatch_level_2_split_valid_x.h5'\n",
        "valid_y_name = 'camelyonpatch_level_2_split_valid_y.h5'\n",
        "\n",
        "meta_train_name = 'camelyonpatch_level_2_split_train_meta.csv'\n",
        "meta_valid_name = 'camelyonpatch_level_2_split_valid_meta.csv'\n",
        "meta_test_name  = 'camelyonpatch_level_2_split_test_meta.csv'\n",
        "\n",
        "# uzip_file(train_x_name + '.gz', train_x_name)\n",
        "# uzip_file(train_y_name + '.gz', train_y_name)\n",
        "\n",
        "# uzip_file(test_x_name + '.gz', test_x_name)\n",
        "# uzip_file(test_y_name + '.gz', test_y_name)\n",
        "\n",
        "# uzip_file(valid_x_name + '.gz', valid_x_name)\n",
        "# uzip_file(valid_y_name + '.gz', valid_y_name)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Kntkpnkm7VM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import HDF5Matrix, normalize\n",
        "import pandas as pd\n",
        "\n",
        "x_train = HDF5Matrix(train_x_name, 'x')\n",
        "y_train = HDF5Matrix(train_y_name, 'y')\n",
        "\n",
        "x_valid = HDF5Matrix(valid_x_name, 'x')\n",
        "y_valid = HDF5Matrix(valid_y_name, 'y')\n",
        "\n",
        "x_test = HDF5Matrix(test_x_name, 'x')\n",
        "y_test = HDF5Matrix(test_y_name, 'y')\n",
        "\n",
        "meta_train = pd.read_csv(meta_train_name)\n",
        "meta_valid = pd.read_csv(meta_valid_name)\n",
        "meta_test  = pd.read_csv(meta_test_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hq5Ys3Cm_-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(x_train))\n",
        "print(type(x_train))\n",
        "print(type(x_train[0]))\n",
        "print(x_train[0].shape)\n",
        "from matplotlib import pyplot\n",
        "for i in range(0, 9):\n",
        "\tpyplot.subplot(330 + 1 + i)\n",
        "\tpyplot.imshow(x_train[i], cmap=pyplot.get_cmap('gray'))\n",
        "pyplot.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubgVQHApnCT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "current_core = 32\n",
        "full_size = current_core * current_core * 3\n",
        "original_shape = (96, 96, 3)\n",
        "new_shape = (current_core, current_core, 3)\n",
        "new_size = (current_core, current_core)\n",
        "\n",
        "import numpy as np\n",
        "# import cv2 as cv\n",
        "# def resize_for_train(x_array, x_shape):\n",
        "#   return np.array([cv.resize(elem, dsize=x_shape) for elem in x_array])\n",
        "# x_train = resize_for_train(x_train, new_size)\n",
        "# x_valid = resize_for_train(x_valid, new_size)\n",
        "# x_test  = resize_for_train(x_test,  new_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG44ZHO0nAkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout, Activation\n",
        "from keras.regularizers import l2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras_metrics as ksm\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import np_utils\n",
        "\n",
        "def plot_metrics(code_metrics, name_metrics):\n",
        "    plt.plot(history.history[code_metrics])\n",
        "    plt.plot(history.history['val_' + code_metrics])\n",
        "    plt.title('Model ' + name_metrics)\n",
        "    plt.ylabel(name_metrics)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "def show_metrics(list_metrics, name_stage, name_model):\n",
        "    name_metrics = ['accuracy', 'precision', 'recall', 'f1-score']\n",
        "    for i in range(4):\n",
        "        print(name_model + ' ' + name_stage + ' ' + \n",
        "              name_metrics[i] + ' : ' + str(list_metrics[i + 1] * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZNXxRk-nFIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name_model = 'CNN with MaxPooling'\n",
        "model = Sequential([\n",
        "    # --------------------------------------------------------------------#\n",
        "    # CONV => RELU => POOL\n",
        "\t\tConv2D(32, (3, 3), padding=\"same\", input_shape=original_shape),\n",
        "\t\tActivation(\"relu\"),\n",
        "\t\tBatchNormalization(),\n",
        "\t\tMaxPooling2D(pool_size=(3, 3)),\n",
        "\t\tDropout(0.25),\n",
        "    # --------------------------------------------------------------------#\n",
        "\t\t# (CONV => RELU) * 2 => POOL\n",
        "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
        "\t\tActivation(\"relu\"),\n",
        "\t\tBatchNormalization(),\n",
        "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
        "\t\tActivation(\"relu\"),\n",
        "\t\tBatchNormalization(),\n",
        "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
        "\t\tDropout(0.25),\n",
        "    # --------------------------------------------------------------------#\n",
        "\t\t# (CONV => RELU) * 2 => POOL\n",
        "\t\tConv2D(128, (3, 3), padding=\"same\"),\n",
        "\t\tActivation(\"relu\"),\n",
        "\t\tBatchNormalization(),\n",
        "\t\tConv2D(128, (3, 3), padding=\"same\"),\n",
        "\t\tActivation(\"relu\"),\n",
        "\t\tBatchNormalization(),\n",
        "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
        "    # --------------------------------------------------------------------#\n",
        "    Flatten(),\n",
        "\t\tDense(1024),\n",
        "\t\tActivation(\"relu\"),\n",
        "\t\tBatchNormalization(),\n",
        "\t\tDropout(0.5),\n",
        "\t\tDense(1),\n",
        "\t\tActivation(\"sigmoid\"),\n",
        "    # --------------------------------------------------------------------#\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy', optimizer='sgd', \n",
        "              metrics = ['binary_accuracy', \n",
        "                         ksm.binary_precision(), \n",
        "                         ksm.binary_recall(),\n",
        "                         ksm.binary_f1_score()\n",
        "                        ]\n",
        "             )\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_train = y_train.reshape((y_train.shape[0], 1))\n",
        "\n",
        "y_valid = np.array(y_valid)\n",
        "y_valid = y_valid.reshape((y_valid.shape[0], 1))\n",
        "\n",
        "y_test = np.array(y_test)\n",
        "y_test = y_test.reshape((y_test.shape[0], 1))\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "              preprocessing_function=lambda x: x/255.,\n",
        "              width_shift_range=2,   # randomly shift images horizontally\n",
        "              height_shift_range=2,  # randomly shift images vertically \n",
        "              horizontal_flip=True,  # randomly flip images\n",
        "              vertical_flip=True)    # randomly flip images\n",
        "\n",
        "batch_size = 1\n",
        "history = model.fit_generator(\n",
        "    datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "    steps_per_epoch=len(x_train) // batch_size,\n",
        "    epochs=10, \n",
        "    shuffle='batch', \n",
        "    use_multiprocessing=True,\n",
        "    validation_data=datagen.flow(x_valid, y_valid, batch_size=batch_size)\n",
        "    )\n",
        "\n",
        "plot_metrics('loss', 'Loss')\n",
        "plot_metrics('binary_accuracy',  'Accuracy')\n",
        "\n",
        "show_metrics(model.evaluate(x_train, y_train), 'train', name_model)\n",
        "show_metrics(model.evaluate(x_valid, y_valid), 'valid', name_model)\n",
        "show_metrics(model.evaluate(x_test,  y_test),  'test',  name_model)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}